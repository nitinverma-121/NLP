{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Stemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#spacy do not support stemming\n",
    "import nltk\n",
    "from nltk.stem import PorterStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "laugh\n",
      "play\n",
      "read\n"
     ]
    }
   ],
   "source": [
    "stemmer= PorterStemmer()\n",
    "\n",
    "a= [\"laughing\", \"playing\", \"reading\"]\n",
    "\n",
    "for word in a:\n",
    "    print(stemmer.stem(word))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "nlp= spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i  |  I\n",
      "ate  |  eat\n",
      "a  |  a\n",
      "few  |  few\n",
      "mangoes  |  mango\n",
      "while  |  while\n",
      "crossing  |  cross\n",
      "the  |  the\n",
      "road  |  road\n",
      ".  |  .\n",
      "They  |  they\n",
      "were  |  be\n",
      "tasty  |  tasty\n",
      ".  |  .\n"
     ]
    }
   ],
   "source": [
    "text= \"i ate a few mangoes while crossing the road. They were tasty.\"\n",
    "\n",
    "doc= nlp(text)\n",
    "\n",
    "for token in doc:\n",
    "    print(token, \" | \", token.lemma_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['tok2vec', 'tagger', 'parser', 'attribute_ruler', 'lemmatizer', 'ner']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp.pipe_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "text= \"i am crazy bruh. i have a very hard past brah.\"\n",
    "doc= nlp(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i  |  I\n",
      "am  |  be\n",
      "crazy  |  crazy\n",
      "bruh  |  bruh\n",
      ".  |  .\n",
      "i  |  I\n",
      "have  |  have\n",
      "a  |  a\n",
      "very  |  very\n",
      "hard  |  hard\n",
      "past  |  past\n",
      "brah  |  Brother\n",
      ".  |  .\n"
     ]
    }
   ],
   "source": [
    "for token in doc: \n",
    "    print(token, \" | \", token.lemma_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "#customize the lemma we have and add new possibiities\n",
    "my_lemma= nlp.get_pipe('attribute_ruler')\n",
    "my_lemma\n",
    "\n",
    "my_lemma = nlp.get_pipe('attribute_ruler')\n",
    "\n",
    "my_lemma.add([[{\"TEXT\":\"bruh\"}],[{\"TEXT\":\"brah\"}]],{\"LEMMA\":\"Brother\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i  |  I\n",
      "am  |  be\n",
      "crazy  |  crazy\n",
      "bruh  |  bruh\n",
      ".  |  .\n",
      "i  |  I\n",
      "have  |  have\n",
      "a  |  a\n",
      "very  |  very\n",
      "hard  |  hard\n",
      "past  |  past\n",
      "brah  |  Brother\n",
      ".  |  .\n"
     ]
    }
   ],
   "source": [
    "for token in doc: \n",
    "    print(token, \" | \", token.lemma_)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exercise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert these list of words into base form using Stemming and Lemmatization and observe the transformations\n",
    "\n",
    "lst_words = ['running', 'painting', 'walking', 'dressing', 'likely', 'children', 'whom', 'good', 'ate', 'fishing']\n",
    "\n",
    "\n",
    "stem_words= []\n",
    "\n",
    "import nltk\n",
    "from nltk.stem import PorterStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['run', 'paint', 'walk', 'dress', 'like', 'children', 'whom', 'good', 'ate', 'fish']\n"
     ]
    }
   ],
   "source": [
    "stemmer= PorterStemmer()\n",
    "\n",
    "for word in lst_words:\n",
    "    stem_words.append(stemmer.stem(word))\n",
    "\n",
    "print(stem_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['run', 'paint', 'walk', 'dress', 'like', 'child', 'whom', 'good', 'eat', 'fish']\n"
     ]
    }
   ],
   "source": [
    "final_array= []\n",
    "\n",
    "for word in stem_words:\n",
    "    t= nlp(word)\n",
    "    for token in t:\n",
    "        final_array.append(token.lemma_)\n",
    "\n",
    "print(final_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert into base form using stemming and lemmatization\n",
    "\n",
    "text = \"\"\"Latha is very multi talented girl.She is good at many skills like dancing, running, singing, playing.She also likes eating Pav Bhagi. she has a \n",
    "habit of fishing and swimming too.Besides all this, she is a wonderful at cooking too.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "latha is veri multi talent girl . she is good at mani skill like danc , run , sing , play . she also like eat pav bhagi . she ha a \n",
      " habit of fish and swim too . besid all thi , she is a wonder at cook too . \n",
      "\n"
     ]
    }
   ],
   "source": [
    "#stemming\n",
    "stemmer= PorterStemmer()\n",
    "\n",
    "word= []\n",
    "\n",
    "for sen in doc.sents:\n",
    "    for words in sen:\n",
    "        word.append(words.text)\n",
    "\n",
    "\n",
    "ans= []\n",
    "for a in word:\n",
    "    ans.append(stemmer.stem(a))\n",
    "\n",
    "finalans= ' '.join(ans)\n",
    "print(finalans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Latha be very multi talented girl . she be good at many skill like dancing , running , singing , play . she also like eat Pav Bhagi . she have a \n",
      " habit of fishing and swim too . besides all this , she be a wonderful at cook too . \n",
      "\n"
     ]
    }
   ],
   "source": [
    "#lemma\n",
    "\n",
    "text = \"\"\"Latha is very multi talented girl.She is good at many skills like dancing, running, singing, playing.She also likes eating Pav Bhagi. she has a \n",
    "habit of fishing and swimming too.Besides all this, she is a wonderful at cooking too.\n",
    "\"\"\"\n",
    "\n",
    "ans= []\n",
    "\n",
    "doc= nlp(text)\n",
    "\n",
    "for token in doc:\n",
    "    ans.append(token.lemma_)\n",
    "\n",
    "finalans= ' '.join(ans)\n",
    "\n",
    "print(finalans)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
